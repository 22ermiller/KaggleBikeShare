rename(
"Acct" = "AccountNum",
"Kiss ID" = "KissID",
"Attend stat" = "AttendStat",
"Tot cost" = "TotalCost",
"Aid exp" = "AidExp",
"Aid Rcv" = "AidRcv",
"Aid Due" = "AidDue",
"Tot hrs" = "TotalHours",
"Sched hrs" = "SchedHours",
"Remain hrs" = "RemainingHours",
"Wk hrs" = "WorkHours",
"Start" = "StartDate",
"Rev grad" = "RevGrad",
"Drop" = "DropDate",
"Leave start" = "LeaveStart",
"Leave end" = "LeaveEnd",
"Reenrolled" = "ReEnrolled",
"Dep stat" = "DepStat"
) %>%
group_by(`Kiss ID`, Acct) %>%
arrange(desc(ImportDate)) %>%
slice_head(n = 1) %>%
ungroup() %>%
left_join(school_codes, by = c("Kiss ID" = "kiss_id")) %>%
left_join(program, by = c("Program" = "Program")) %>%
mutate(WAvg = as.numeric(WAvg),
PAvg = as.numeric(PAvg),
Balance = as.numeric(Balance),
`Tot cost` = as.numeric(`Tot cost`),
`Aid exp` = as.numeric(`Aid exp`),
`Aid Rcv` = as.numeric(`Aid Rcv`),
`Aid Due` = as.numeric(`Aid Due`),
) %>%
mutate(across(Start:Reenrolled, ~as.Date(.)))  %>%
mutate(revised_program = case_when(`Wk hrs` < 24 & revised_program == "Cosmetology"~ "Cosmetology_PT",
`Wk hrs` >= 24 & revised_program == "Cosmetology" ~ "Cosmetology_FT",
TRUE ~ revised_program),
date_pulled = floor_date(ImportDate, "week"))
View(adhoc_df)
unique(adhoc_df$ImportDate)
adhoc <- read_csv("Downloads/AdHocExportFreedom_20230806.csv")
adhoc %>% filter(`Kiss ID` == 5734)
unique(adhoc$`Kiss ID`)
View(school_codes)
merged_attendance_df %>% filter(bus_name == "Rexburg") %>% View()
merged_attendance_df <- azure_db_connection %>% tbl("ScorecardAttendance") %>%
#filter(KissID %in% kiss_ids_to_filter) %>%
collect()
merged_attendance_df %>% filter(KissID == 5734) %>% View()
library(lubridate)
merged_attendance_df %>% filter(KissID == 5734) %>% mutate(Date = mdy(BeginningDate) %>% View()
)
merged_attendance_df %>% filter(KissID == 5734) %>% mutate(Date = mdy(BeginningDate)) %>% View()
scorecard <- read_csv("Documents/Work/Executive Dashboard/test/Data/school_codes.csv")
scorecard <- read_csv("Documents/Work/Executive Dashboard/test/Data/scorecard_data.csv")
scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% View()
scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01")
scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01") %>% filter(enrolled == 0)
scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01") %>% filter(enrolled < 5)
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01")
unique(filtered_scorecard$School)
View(school_codes)
schools <- tibble(bus_name = unique(filtered_scorecard$School))
anti_join(school_codes, schools, by = "bus_name")
View(filtered_scorecard)
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01")
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`))
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" & Date == "2023-01-01")
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01")
schools <- tibble(bus_name = unique(filtered_scorecard$School))
anti_join(school_codes, schools, by = "bus_name")
View(scorecard)
View(schools)
View(school_codes)
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2023-01-01")
schools <- tibble(bus_name = unique(filtered_scorecard$School))
anti_join(school_codes, schools, by = "bus_name")
library(gmailr)
library(tidyverse)
gm_auth("evan@staritasolutions.com", cache = FALSE)
gm_auth_configure(path = "~/Downloads/official_gmail_client_secret.json")
gm_auth("evan@staritasolutions.com", cache = FALSE)
gm_profile()
library(lubridate)
library(odbc)
library(tidyverse)
library(janitor)
my_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.3.so.1.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
library(readr)
school_codes <- read_csv("Documents/Work/Executive Dashboard/CincinnatiExecDash/Data/school_codes.csv")
View(school_codes)
adhoc <- my_connection %>% tbl("AdHocExports") %>% filter(KissID == 5810) %>% collect()
adhoc1 <- adhoc %>%
group_by(`Kiss ID`, Acct) %>%
arrange(desc(ImportDate)) %>%
slice_head(n = 1) %>%
ungroup()
adhoc1 <- adhoc %>%
group_by(KissID) %>%
arrange(desc(ImportDate)) %>%
slice_head(n = 1) %>%
ungroup()
adhoc1 <- adhoc %>%
group_by(AccountNum) %>%
arrange(desc(ImportDate)) %>%
slice_head(n = 1) %>%
ungroup()
adhoc1 %>% filter(AttendStat == "Currently Attending")
View(adhoc1)
library(lubridate)
library(odbc)
library(tidyverse)
library(janitor)
# df <- read_csv("~/Downloads/ProgramAttendance.csv")
school_codes <- read_csv("~/Documents/Work/Executive Dashboard/test/Data/school_codes.csv")
my_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.3.so.1.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
my_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.3.so.1.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
# Pull From Database ------------------------------------------------------
attendance_df_raw <- my_connection %>% tbl("ScorecardAttendance") %>% collect()
attendance_df <- attendance_df_raw %>%
mutate(BeginningDate = mdy(BeginningDate),
EndDate = mdy(EndDate)) %>%
rename(Beginning_Date = BeginningDate,
End_Date = EndDate,
Kiss_ID = KissID,
Actual_Hours = ActualHours,
Scheduled_Hours = ScheduledHours) %>%
select(-(id))
View(school_codes)
attendance_df %>% filter(Kiss_ID %in% c("5778")) %>% View()
View(school_codes)
attendance_df %>% filter(Kiss_ID %in% c("1065")) %>% View()
attendance_df %>% filter(Kiss_ID %in% c("5778")) %>% View()
attendance_df %>% filter(Kiss_ID %in% c("5751")) %>% View()
library(tidyverse)
crm <- read_csv("Downloads/northstar_crm(2).csv")
View(crm)
?str_detect
crm %>% filter(str_detect(`URL Source`, "GFF"))
crm %>% filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Boise") %>%
filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Boise") %>%
filter(str_detect(`URL Source`, "gff")) %>%
View()
?str_detect
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Boise") %>%
filter(str_detect(`URL Source`, "gff")) %>%
View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
mutate(lead_num = n()) %>%
View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
crm %>%
#filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
crm %>%
# filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
# filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
unique(crm$`School Name`)
library(tidyverse)
crm <- read_csv("Downloads/northstar_crm(3).csv")
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Provo") %>%
filter(str_detect(`URL Source`, "gff")) %>%
)
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "P") %>%
filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Provo") %>%
filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Provo") %>%
filter(str_detect(`URL Source`, "gff")) %>% View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Provo") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
3250000000/3300000
32500000/3300000
45000000/5600000
11.11+9.85+8.04
29/3
20000000/1800000
library(tidymodels)
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
install.packages(c("askpass", "attachment", "AzureGraph", "broom", "bs4Dash", "bslib", "charlatan", "chromote", "config", "cpp11", "credentials", "curl", "dbplyr", "deSolve", "downlit", "dplyr", "DT", "evaluate", "fields", "fontawesome", "gert", "ggplot2", "ggpp", "glmnet", "golem", "googledrive", "googlesheets4", "gtable", "haven", "htmltools", "httr", "httr2", "knitr", "ks", "labeling", "lme4", "locfit", "markdown", "MatrixModels", "matrixStats", "minqa", "mvtnorm", "odbc", "openssl", "packrat", "pak", "patchwork", "pkgbuild", "pkgload", "plotly", "pROC", "processx", "profvis", "promises", "purrr", "quantreg", "readxl", "rematch", "rmarkdown", "rsconnect", "rstan", "rstudioapi", "shiny", "shinyWidgets", "snakecase", "StanHeaders", "sys", "testthat", "thematic", "tidybayes", "tinytex", "tzdb", "usethis", "uuid", "V8", "vctrs", "viridis", "viridisLite", "waldo", "webshot2", "xfun", "xml2"))
install.packages(c("askpass", "attachment", "AzureGraph", "broom", "bs4Dash", "bslib", "charlatan", "chromote", "config", "cpp11", "credentials", "curl", "dbplyr", "deSolve", "downlit", "dplyr", "DT", "evaluate", "fields", "fontawesome", "gert", "ggplot2", "ggpp", "glmnet", "golem", "googledrive", "googlesheets4", "gtable", "haven", "htmltools", "httr", "httr2", "knitr", "ks", "labeling", "lme4", "locfit", "markdown", "MatrixModels", "matrixStats", "minqa", "mvtnorm", "odbc", "openssl", "packrat", "pak", "patchwork", "pkgbuild", "pkgload", "plotly", "pROC", "processx", "profvis", "promises", "purrr", "quantreg", "readxl", "rematch", "rmarkdown", "rsconnect", "rstan", "rstudioapi", "shiny", "shinyWidgets", "snakecase", "StanHeaders", "sys", "testthat", "thematic", "tidybayes", "tinytex", "tzdb", "usethis", "uuid", "V8", "vctrs", "viridis", "viridisLite", "waldo", "webshot2", "xfun", "xml2"))
install.packages("tidymodels")
dbimon(1,5,.2)
dbinom(1,5,.2)
?choose
choose(5,1)
dbinom(0,5,.2)
dbinom(2,5,.2)
dbinom(3,5,.2)
dbinom(4,5,.2)
dbinom(5,5,.2)
bike_train <- vroom("./train.csv") %>%
select(-casual, -registered)
bike_test <- vroom("./test.csv")
library(tidyverse)
library(vroom)
library(tidymodels)
setwd("~/Documents/Stat 348/KaggleBikeShare")
bike_train <- vroom("./train.csv") %>%
select(-casual, -registered)
bike_test <- vroom("./test.csv")
install.packages("glmnet")
penalized_recipe <- recipe(count~., data = bike_train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_mutate(weather = as.factor(weather),
season = as.factor(season),
workingday = as.factor(workingday),
holiday = as.factor(holiday)) %>%
step_time(datetime, features= c("hour")) %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
penalized_recipe <- recipe(count~., data = bike_train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_mutate(weather = as.factor(weather),
season = as.factor(season),
workingday = as.factor(workingday),
holiday = as.factor(holiday)) %>%
step_time(datetime, features= c("hour")) %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
# Penalized Regression Model
penalized_model <- linear_reg(penalty = 5, mixture = .3) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train)
bike_train_log <- bike_train %>%
mutate(count = log(count))
penalized_recipe <- recipe(count~., data = bike_train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_mutate(weather = as.factor(weather),
season = as.factor(season),
workingday = as.factor(workingday),
holiday = as.factor(holiday)) %>%
step_time(datetime, features= c("hour")) %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
# Penalized Regression Model
penalized_model <- linear_reg(penalty = 5, mixture = .3) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
penalized_recipe <- recipe(count~., data = bike_train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_mutate(weather = as.factor(weather),
season = as.factor(season),
workingday = as.factor(workingday),
holiday = as.factor(holiday)) %>%
step_time(datetime, features= c("hour")) %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
# Penalized Regression Model
penalized_model <- linear_reg(penalty = 5, mixture = .3) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = e^(bike_penalized_predictions$.pred))
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_pois_predictions, "final_penalized_predictions.csv", delim = ",")
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
View(final_penalized_predictions)
# Penalized Regression Model
penalized_model <- linear_reg(penalty = 1, mixture = .3) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
View(final_penalized_predictions)
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
# Penalized Regression Model
penalized_model <- poisson_reg(penalty = 1, mixture = .3) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
# Penalized Regression Model
penalized_model <- poisson_reg(penalty = 1, mixture = .3) %>% # Set model and Tuning
set_engine("glm") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
# Penalized Regression Model
penalized_model <- linear_reg(penalty = 1, mixture = .3) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
penalized_recipe <- recipe(count~., data = bike_train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_mutate(weather = as.factor(weather),
season = as.factor(season),
workingday = as.factor(workingday),
holiday = as.factor(holiday)) %>%
step_time(datetime, features= c("hour", "day")) %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
?step_time
penalized_recipe <- recipe(count~., data = bike_train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_mutate(weather = as.factor(weather),
season = as.factor(season),
workingday = as.factor(workingday),
holiday = as.factor(holiday)) %>%
step_time(datetime, features= c("hour", "wday")) %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
penalized_recipe <- recipe(count~., data = bike_train) %>%
step_mutate(weather = ifelse(weather == 4, 3, weather)) %>%
step_mutate(weather = as.factor(weather),
season = as.factor(season),
workingday = as.factor(workingday),
holiday = as.factor(holiday)) %>%
step_time(datetime, features= c("hour")) %>%
step_rm(datetime) %>%
step_dummy(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors())
# Penalized Regression Model
penalized_model <- linear_reg(penalty = .5, mixture = .3) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
# Penalized Regression Model
penalized_model <- linear_reg(penalty = .5, mixture = .8) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
# Penalized Regression Model
penalized_model <- linear_reg(penalty = .5, mixture = .2) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
# Penalized Regression Model
penalized_model <- linear_reg(penalty = .5, mixture = .1) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
# Penalized Regression Model
penalized_model <- linear_reg(penalty = .5, mixture = .05) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
# Penalized Regression Model
penalized_model <- linear_reg(penalty = .5, mixture = 0) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
# Penalized Regression Model
penalized_model <- linear_reg(penalty = .2, mixture = 0) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
# Penalized Regression Model
penalized_model <- linear_reg(penalty = 0, mixture = 0) %>% # Set model and Tuning
set_engine("glmnet") # Function to fit in R
penalized_workflow <- workflow() %>%
add_recipe(penalized_recipe) %>%
add_model(penalized_model) %>%
fit(data = bike_train_log)
predict(penalized_workflow, new_data = bike_test)
bike_penalized_predictions <- predict(penalized_workflow,
new_data = bike_test)
final_penalized_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_penalized_predictions$.pred))
final_penalized_predictions$datetime <- as.character(format(final_penalized_predictions$datetime))
vroom_write(final_penalized_predictions, "final_penalized_predictions.csv", delim = ",")
min(final_penalized_predictions$count)
