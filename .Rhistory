"bus_name" = "bus_name"
)
) %>%
filter(date >= first_date) %>%
group_by(bus_name, revised_program) %>%
arrange(bus_name, revised_program, date) %>%
mutate_at(vars(start_n:reenroll_n), ~ replace(., is.na(.), 0)) %>%
mutate(enrollment_net = start_n - grad_n - drop_n,
loa_dif = loa_start_n - loa_end_n) %>%
mutate(
enrollment_end = cumsum(enrollment_net),
enrollment_start = enrollment_end - enrollment_net,
current_loa = cumsum(loa_dif)
) %>%
ungroup()
final_df2 <- final_df %>%
rename(
School = bus_name,
Date = date,
Program = revised_program,
`New Starts` = start_n,
`Start Enrollment` = enrollment_start,
Reenroll = reenroll_n,
Grads = grad_n,
Drops = drop_n,
`New LOAs` = loa_start_n,
`LOA Ended` = loa_end_n,
`Current LOAs` = current_loa,
`End Enrollment` = enrollment_end
)
my_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.2.so.2.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
# Pull From Database ------------------------------------------------------
attendance_df_raw <- my_connection %>% tbl("ScorecardAttendance") %>% collect()
library(janitor)
get_dupes(attendance_df_raw, id)
get_azure_token(resource ="ss-solutions-server.database.windows.net" ,
tenant = "common",
app = "a927ac33-127f-4c6e-9e4b-7074440d344e",
use_cache = FALSE)
library(AzureStor)
library(AzureAuth)
library(odbc)
library(AzureRMR)
tok <- get_azure_token(resource ="ss-solutions-server.database.windows.net" ,
tenant = "common",
app = "a927ac33-127f-4c6e-9e4b-7074440d344e",
use_cache = FALSE)
tok <- get_azure_token(resource ="ss-solutions-server.database.windows.net" ,
tenant = "common",
app = "a927ac33-127f-4c6e-9e4b-7074440d344e",
use_cache = FALSE)
list_azure_tokens()
library(lubridate)
library(odbc)
library(tidyverse)
library(janitor)
# df <- read_csv("~/Downloads/ProgramAttendance.csv")
school_codes <- read_csv("~/Documents/Work/Executive Dashboard/test/Data/school_codes.csv")
my_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.2.so.2.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
View(school_codes)
# Pull From Database ------------------------------------------------------
attendance_df_raw <- my_connection %>% tbl("ScorecardAttendance") %>% filter(KissID %in% c(7682, 5778, 5751) %>% collect()
)
# Pull From Database ------------------------------------------------------
attendance_df_raw <- my_connection %>% tbl("ScorecardAttendance") %>% filter(KissID %in% c(7682, 5778, 5751)) %>% collect()
View(attendance_df_raw)
attendance_df <- attendance_df_raw %>%
mutate(BeginningDate = mdy(BeginningDate),
EndDate = mdy(EndDate)) %>%
rename(Beginning_Date = BeginningDate,
End_Date = EndDate,
Kiss_ID = KissID,
Actual_Hours = ActualHours,
Scheduled_Hours = ScheduledHours) %>%
select(-(id))
View(attendance_df)
attendance_df %>% filter(Beginning_Date >= "2023-01-01") %>% group_by(Kiss_ID, Program) %>% summarize(n())
188/30
gc()
library(tidyverse)
program <- read_csv("Documents/Work/Executive Dashboard/MichiganExecDash/Data/program.csv")
school_codes <- read_csv("Documents/Work/Executive Dashboard/MichiganExecDash/Data/school_codes.csv")
azure_db_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.2.so.2.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
library(AzureStor)
library(data.table)
library(lubridate)
library(magrittr)
library(dplyr)
library(odbc)
library(tidyr)
azure_db_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.2.so.2.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
endp <- storage_endpoint("https://ersdata.blob.core.windows.net",
key = "Nc6Avd2msMkfsLFTGMO24YT94BcYjffF0Pw/AnVZnmcS2fJqthqeEMnbjcMfeqQZwPbWLhoSsT/B+AStTjmBjQ==")
#get specific container
cont <- storage_container(endp, "ersdata")
merged_attendance_df <- azure_db_connection %>% tbl("ScorecardAttendance") %>%
#filter(KissID %in% kiss_ids_to_filter) %>%
collect() %>%
mutate(EndDate = mdy(EndDate)) %>%
mutate(Date = floor_date(EndDate, unit = "month")) %>%
left_join(school_codes, by = c("KissID" = "kiss_id")) %>%
left_join(program, by = "Program") %>%
dplyr::select(-EndDate, -BeginningDate) %>%
group_by(Date, bus_name, revised_program) %>%
summarise(Actual_Hours = sum(ActualHours),
Scheduled_Hours = sum(ScheduledHours)) %>%
ungroup()
adhoc_df <- azure_db_connection %>% tbl("AdHocExports") %>%
#filter(KissID %in% kiss_ids_to_filter) %>%
collect() %>%
rename(
"Acct" = "AccountNum",
"Kiss ID" = "KissID",
"Attend stat" = "AttendStat",
"Tot cost" = "TotalCost",
"Aid exp" = "AidExp",
"Aid Rcv" = "AidRcv",
"Aid Due" = "AidDue",
"Tot hrs" = "TotalHours",
"Sched hrs" = "SchedHours",
"Remain hrs" = "RemainingHours",
"Wk hrs" = "WorkHours",
"Start" = "StartDate",
"Rev grad" = "RevGrad",
"Drop" = "DropDate",
"Leave start" = "LeaveStart",
"Leave end" = "LeaveEnd",
"Reenrolled" = "ReEnrolled",
"Dep stat" = "DepStat"
) %>%
group_by(`Kiss ID`, Acct) %>%
arrange(desc(ImportDate)) %>%
slice_head(n = 1) %>%
ungroup() %>%
left_join(school_codes, by = c("Kiss ID" = "kiss_id")) %>%
left_join(program, by = c("Program" = "Program")) %>%
mutate(WAvg = as.numeric(WAvg),
PAvg = as.numeric(PAvg),
Balance = as.numeric(Balance),
`Tot cost` = as.numeric(`Tot cost`),
`Aid exp` = as.numeric(`Aid exp`),
`Aid Rcv` = as.numeric(`Aid Rcv`),
`Aid Due` = as.numeric(`Aid Due`),
) %>%
mutate(across(Start:Reenrolled, ~as.Date(.)))  %>%
mutate(revised_program = case_when(`Wk hrs` < 24 & revised_program == "Cosmetology"~ "Cosmetology_PT",
`Wk hrs` >= 24 & revised_program == "Cosmetology" ~ "Cosmetology_FT",
TRUE ~ revised_program),
date_pulled = floor_date(ImportDate, "week"))
View(adhoc_df)
unique(adhoc_df$ImportDate)
adhoc <- read_csv("Downloads/AdHocExportFreedom_20230806.csv")
adhoc %>% filter(`Kiss ID` == 5734)
unique(adhoc$`Kiss ID`)
View(school_codes)
merged_attendance_df %>% filter(bus_name == "Rexburg") %>% View()
merged_attendance_df <- azure_db_connection %>% tbl("ScorecardAttendance") %>%
#filter(KissID %in% kiss_ids_to_filter) %>%
collect()
merged_attendance_df %>% filter(KissID == 5734) %>% View()
library(lubridate)
merged_attendance_df %>% filter(KissID == 5734) %>% mutate(Date = mdy(BeginningDate) %>% View()
)
merged_attendance_df %>% filter(KissID == 5734) %>% mutate(Date = mdy(BeginningDate)) %>% View()
scorecard <- read_csv("Documents/Work/Executive Dashboard/test/Data/school_codes.csv")
scorecard <- read_csv("Documents/Work/Executive Dashboard/test/Data/scorecard_data.csv")
scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% View()
scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01")
scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01") %>% filter(enrolled == 0)
scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01") %>% filter(enrolled < 5)
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01")
unique(filtered_scorecard$School)
View(school_codes)
schools <- tibble(bus_name = unique(filtered_scorecard$School))
anti_join(school_codes, schools, by = "bus_name")
View(filtered_scorecard)
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" | Date == "2023-01-01")
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`))
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01" & Date == "2023-01-01")
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2019-01-01")
schools <- tibble(bus_name = unique(filtered_scorecard$School))
anti_join(school_codes, schools, by = "bus_name")
View(scorecard)
View(schools)
View(school_codes)
filtered_scorecard <- scorecard %>% filter(Date >= "2019-01-01") %>% group_by(School, Date) %>% summarize(enrolled = sum(`End Enrollment`)) %>% filter(Date == "2023-01-01")
schools <- tibble(bus_name = unique(filtered_scorecard$School))
anti_join(school_codes, schools, by = "bus_name")
library(gmailr)
library(tidyverse)
gm_auth("evan@staritasolutions.com", cache = FALSE)
gm_auth_configure(path = "~/Downloads/official_gmail_client_secret.json")
gm_auth("evan@staritasolutions.com", cache = FALSE)
gm_profile()
library(lubridate)
library(odbc)
library(tidyverse)
library(janitor)
my_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.3.so.1.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
library(readr)
school_codes <- read_csv("Documents/Work/Executive Dashboard/CincinnatiExecDash/Data/school_codes.csv")
View(school_codes)
adhoc <- my_connection %>% tbl("AdHocExports") %>% filter(KissID == 5810) %>% collect()
adhoc1 <- adhoc %>%
group_by(`Kiss ID`, Acct) %>%
arrange(desc(ImportDate)) %>%
slice_head(n = 1) %>%
ungroup()
adhoc1 <- adhoc %>%
group_by(KissID) %>%
arrange(desc(ImportDate)) %>%
slice_head(n = 1) %>%
ungroup()
adhoc1 <- adhoc %>%
group_by(AccountNum) %>%
arrange(desc(ImportDate)) %>%
slice_head(n = 1) %>%
ungroup()
adhoc1 %>% filter(AttendStat == "Currently Attending")
View(adhoc1)
library(lubridate)
library(odbc)
library(tidyverse)
library(janitor)
# df <- read_csv("~/Downloads/ProgramAttendance.csv")
school_codes <- read_csv("~/Documents/Work/Executive Dashboard/test/Data/school_codes.csv")
my_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.3.so.1.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
my_connection <- dbConnect(drv = odbc::odbc(),
driver = "/opt/microsoft/msodbcsql18/lib64/libmsodbcsql-18.3.so.1.1",
server = "ss-solutions-server.database.windows.net",
database = "CorporateScorecardData",
uid = "staritasolutions",
pwd = "jje&2023FTW")
# Pull From Database ------------------------------------------------------
attendance_df_raw <- my_connection %>% tbl("ScorecardAttendance") %>% collect()
attendance_df <- attendance_df_raw %>%
mutate(BeginningDate = mdy(BeginningDate),
EndDate = mdy(EndDate)) %>%
rename(Beginning_Date = BeginningDate,
End_Date = EndDate,
Kiss_ID = KissID,
Actual_Hours = ActualHours,
Scheduled_Hours = ScheduledHours) %>%
select(-(id))
View(school_codes)
attendance_df %>% filter(Kiss_ID %in% c("5778")) %>% View()
View(school_codes)
attendance_df %>% filter(Kiss_ID %in% c("1065")) %>% View()
attendance_df %>% filter(Kiss_ID %in% c("5778")) %>% View()
attendance_df %>% filter(Kiss_ID %in% c("5751")) %>% View()
library(tidyverse)
crm <- read_csv("Downloads/northstar_crm(2).csv")
View(crm)
?str_detect
crm %>% filter(str_detect(`URL Source`, "GFF"))
crm %>% filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Boise") %>%
filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Boise") %>%
filter(str_detect(`URL Source`, "gff")) %>%
View()
?str_detect
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Boise") %>%
filter(str_detect(`URL Source`, "gff")) %>%
View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
mutate(lead_num = n()) %>%
View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
crm %>%
#filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
crm %>%
# filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
# filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
unique(crm$`School Name`)
library(tidyverse)
crm <- read_csv("Downloads/northstar_crm(3).csv")
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Provo") %>%
filter(str_detect(`URL Source`, "gff")) %>%
)
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "P") %>%
filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Provo") %>%
filter(str_detect(`URL Source`, "gff"))
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Provo") %>%
filter(str_detect(`URL Source`, "gff")) %>% View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01" & `School Name` == "Provo") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
crm %>%
filter(Lead >= "2023-08-01" & Lead < "2023-09-01") %>%
filter(str_detect(`URL Source`, "gff")) %>%
group_by(`School Name`) %>%
summarize(lead_num = n()) %>%
View()
3250000000/3300000
32500000/3300000
45000000/5600000
11.11+9.85+8.04
29/3
20000000/1800000
library(tidymodels)
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
install.packages("tidymodels")
install.packages(c("askpass", "attachment", "AzureGraph", "broom", "bs4Dash", "bslib", "charlatan", "chromote", "config", "cpp11", "credentials", "curl", "dbplyr", "deSolve", "downlit", "dplyr", "DT", "evaluate", "fields", "fontawesome", "gert", "ggplot2", "ggpp", "glmnet", "golem", "googledrive", "googlesheets4", "gtable", "haven", "htmltools", "httr", "httr2", "knitr", "ks", "labeling", "lme4", "locfit", "markdown", "MatrixModels", "matrixStats", "minqa", "mvtnorm", "odbc", "openssl", "packrat", "pak", "patchwork", "pkgbuild", "pkgload", "plotly", "pROC", "processx", "profvis", "promises", "purrr", "quantreg", "readxl", "rematch", "rmarkdown", "rsconnect", "rstan", "rstudioapi", "shiny", "shinyWidgets", "snakecase", "StanHeaders", "sys", "testthat", "thematic", "tidybayes", "tinytex", "tzdb", "usethis", "uuid", "V8", "vctrs", "viridis", "viridisLite", "waldo", "webshot2", "xfun", "xml2"))
install.packages(c("askpass", "attachment", "AzureGraph", "broom", "bs4Dash", "bslib", "charlatan", "chromote", "config", "cpp11", "credentials", "curl", "dbplyr", "deSolve", "downlit", "dplyr", "DT", "evaluate", "fields", "fontawesome", "gert", "ggplot2", "ggpp", "glmnet", "golem", "googledrive", "googlesheets4", "gtable", "haven", "htmltools", "httr", "httr2", "knitr", "ks", "labeling", "lme4", "locfit", "markdown", "MatrixModels", "matrixStats", "minqa", "mvtnorm", "odbc", "openssl", "packrat", "pak", "patchwork", "pkgbuild", "pkgload", "plotly", "pROC", "processx", "profvis", "promises", "purrr", "quantreg", "readxl", "rematch", "rmarkdown", "rsconnect", "rstan", "rstudioapi", "shiny", "shinyWidgets", "snakecase", "StanHeaders", "sys", "testthat", "thematic", "tidybayes", "tinytex", "tzdb", "usethis", "uuid", "V8", "vctrs", "viridis", "viridisLite", "waldo", "webshot2", "xfun", "xml2"))
install.packages("tidymodels")
dbimon(1,5,.2)
dbinom(1,5,.2)
?choose
choose(5,1)
dbinom(0,5,.2)
dbinom(2,5,.2)
dbinom(3,5,.2)
dbinom(4,5,.2)
dbinom(5,5,.2)
dogs <- function(x,y, prob_a) {
value <- ((y^x)/(factorial(x)*(1+y+(y^2/2)+(y^3/6)+(y^4/24))))*(prob_a)
}
dogs(0,.5,1/10)
a <- dogs(0,.5,1/10)
dogs(0,.5,1/10)
a <- dogs(0,.5,1/10)
a <- dogs(1,.5,1/10)
a <- dogs(2,.5,1/10)
a <- dogs(3,.5,1/10)
a <- dogs(4,.5,1/10)
a <- dogs(2,2,7/10)
a <- dogs(1,2,7/10)
a <- dogs(3,2,7/10)
a <- dogs(4,2,7/10)
a <- dogs(0,1,2/10)
a <- dogs(1,1,2/10)
a <- dogs(2,1,2/10)
a <- dogs(3,1,2/10)
a <- dogs(4,1,2/10)
dogs <- function(x,y) {
value <- ((y^x)/(factorial(x)*(1+y+(y^2/2)+(y^3/6)+(y^4/24))))
print(value)
}
a <- dogs(c(0,1,2,3,4),.5)
a %*% c(0,1,2,3,4)
a
install.packages("rpart")
library(rpart)
library(tidyverse)
library(vroom)
library(tidymodels)
setwd("~/Documents/Stat 348/KaggleBikeShare")
bike_train <- vroom("./train.csv") %>%
select(-casual, -registered)
bike_test <- vroom("./test.csv")
bike_train_log <- bike_train %>%
mutate(count = log(count))
tree_recipe <- recipe(count~., data = bike_train)
tree_model <- decision_tree(tree_depth = tune(),
cost_complexity = tune(),
min_n = tune()) %>%
set_engine("rpart") %>%
set_mode("regression")
# Grid of values to tune over
tuning_grid <- grid_regular(tree_depth(),
cost_complexity(),
min_n())
# Split data for cross validation
folds <- vfold_cv(bike_train_log, v = 10, repeats = 1)
# Run the cross validation
cv_results <- tree_wf %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(rmse,mae,rsq)) # here pick the metrics you are interested in
tree_wf <- workflow() %>%
add_recipe(tree_recipe) %>%
add_model(tree_model)
# Grid of values to tune over
tuning_grid <- grid_regular(tree_depth(),
cost_complexity(),
min_n())
# Split data for cross validation
folds <- vfold_cv(bike_train_log, v = 10, repeats = 1)
# Run the cross validation
cv_results <- tree_wf %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(rmse,mae,rsq)) # here pick the metrics you are interested in
# Plot results
collect_metrics(cv_results) %>%
filter(.metric == "rmse") %>%
ggplot(data = ., aes(x = tree_depth, y = mean, color = factor(min_n))) +
geom_line()
final_wf <- tree_wf %>%
finalize_workflow(bestTune) %>%
fit(data = bike_train_log)
bestTune <- cv_results %>%
select_best("rmse")
final_wf <- tree_wf %>%
finalize_workflow(bestTune) %>%
fit(data = bike_train_log)
# predict
bike_tree_predicions <- predict(final_wf,
new_data = bike_test)
final_tree_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_tree_predicions$.pred))
final_tree_predictions$datetime <- as.character(format(final_tree_predictions$datetime))
vroom_write(final_tree_predictions, "final_tree_predictions.csv", delim = ",")
# Grid of values to tune over
tuning_grid <- grid_regular(tree_depth(),
cost_complexity(),
min_n(),
levels = 10)
# Split data for cross validation
folds <- vfold_cv(bike_train_log, v = 10, repeats = 1)
# Run the cross validation
cv_results <- tree_wf %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(rmse,mae,rsq)) # here pick the metrics you are interested in
# Grid of values to tune over
tuning_grid <- grid_regular(tree_depth(),
cost_complexity(),
min_n(),
levels = 5)
# Split data for cross validation
folds <- vfold_cv(bike_train_log, v = 10, repeats = 1)
# Run the cross validation
cv_results <- tree_wf %>%
tune_grid(resamples = folds,
grid = tuning_grid,
metrics = metric_set(rmse,mae,rsq)) # here pick the metrics you are interested in
# Plot results
collect_metrics(cv_results) %>%
filter(.metric == "rmse") %>%
ggplot(data = ., aes(x = tree_depth, y = mean, color = factor(min_n))) +
geom_line()
bestTune <- cv_results %>%
select_best("rmse")
final_wf <- tree_wf %>%
finalize_workflow(bestTune) %>%
fit(data = bike_train_log)
# predict
bike_tree_predicions <- predict(final_wf,
new_data = bike_test)
final_tree_predictions <- tibble(datetime = bike_test$datetime, count = exp(bike_tree_predicions$.pred))
final_tree_predictions$datetime <- as.character(format(final_tree_predictions$datetime))
vroom_write(final_tree_predictions, "final_tree_predictions.csv", delim = ",")
